# go-polars vs Polars vs Pandas â€“ Benchmark Deep-Dive

> *Last updated: <!--DATE_PLACEHOLDER-->*

![banner](./benchmark_plot.png)

## TL;DR

| Operation | ğŸ† Fastest | go-polars âŸ¶ Polars | go-polars âŸ¶ Pandas |
|-----------|-----------|--------------------|---------------------|
| DataFrame Creation | **go-polars** | up to 75Ã— faster | up to 300Ã— faster |
| Sorting | **Polars** | ~2Ã— slower | â‰ˆ Pandas parity |
| GroupBy & Agg | **Polars** | 13-38Ã— slower | 7-15Ã— slower |

## Setup

* **Hardware**: M-series MacBook Pro (8-core CPU)
* **Software**:
  - go-polars `v0.1.0` (`commit <hash>`)
  - Polars `0.20.x`
  - Pandas `2.2.x`
  - Python `3.11`

## Benchmark script

All numbers were produced with the reusable [`benchmark.py`](./benchmark.py) script:

```bash
python benchmark.py --csv results.csv --plot benchmark_plot.png
```

â€¢ Uses synthetic data with 3Ã— `int64`, 3Ã— `float64`, 3Ã— `bool` columns  
â€¢ Sizes: 1 K â†’ 1 M rows (plus 10 M stress test)  
â€¢ Reports absolute runtime and speed-up ratios

## Results

### 1 â€’ DataFrame Creation

<INSERT_TABLE_CREATION>

### 2 â€’ Sorting

<INSERT_TABLE_SORT>

### 3 â€’ GroupBy + Aggregation

<INSERT_TABLE_GROUPBY>

*(Full CSV in the repo for reproducibility.)*

## Why go-polars crushes creation

1. Zero-copy transfer of NumPy buffers âœ”ï¸
2. Column-oriented allocation in Go âœ”ï¸
3. No GIL â€“ pure Go code across cores âœ”ï¸

## Where Polars still leads

Polarsâ€™ Rust core uses auto-SIMD vectorisation and finely-tuned cache-aware algorithms, especially for groupby kernels. go-polars is catching up â€“ the next release will ship a streaming aggregator and parallel copy which already closed the gap in the **sorting** benchmark.

## Roadmap

- [x] Parallel column copy in sort
- [x] Zero-alloc single-column groupby map
- [ ] Streaming aggregation engine (in-progress)
- [ ] Arrow IPC compatibility layer
- [ ] GPU off-load (CUDA)

Stay tuned! ğŸš€

---

*Feedback welcome â€“ open an issue or ping me on Twitter @yourhandle.* 